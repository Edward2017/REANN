import torch
from torch import nn
from torch import Tensor
from collections import OrderedDict
import numpy as np
import opt_einsum as oe


class GetDensity(torch.nn.Module):
    def __init__(self,rs,inta,cutoff,nipsin,ocmod_list):
        super(GetDensity,self).__init__()
        '''
        rs: tensor[ntype,nwave] float
        inta: tensor[ntype,nwave] float
        nipsin: np.array/list   int
        cutoff: float
        '''
        self.rs=nn.parameter.Parameter(rs)
        self.inta=nn.parameter.Parameter(inta)
        self.register_buffer('cutoff', torch.Tensor([cutoff]))
        self.register_buffer('nipsin', nipsin)
        # save the element-nwave-ipsin-maxnipsin
        ENIM=torch.tensor([int(self.rs.shape[0]),int(self.rs.shape[1]),int(self.nipsin.shape[0]),int(torch.max(nipsin))])
        self.register_buffer('ENIM', ENIM)
        npara=[1]
        index_para=torch.tensor([0],dtype=torch.long)
        for i in range(1,self.ENIM[2]):
           npara.append(int(3**self.nipsin[i]))
           index_para=torch.cat((index_para,torch.ones((npara[i]),dtype=torch.long)*i))

        self.register_buffer('index_para',index_para)
        # index_para: Type: longTensor,index_para was used to expand the dim of params 
        # in nn with para(l) 
        # will have the form index_para[0,|1,1,1|,2,2,2,2,2,2,2,2,2|...npara[l]..\...]
        self.params=nn.parameter.Parameter(2.0*torch.randn(self.ENIM[0],self.ENIM[1]*self.ENIM[2])-1.0)
        ocmod=OrderedDict()
        for i, m in enumerate(ocmod_list):
            f_oc="memssage_"+str(i)
            ocmod[f_oc]= m
        self.ocmod= torch.nn.ModuleDict(ocmod)

    def gaussian(self,distances,species_):
        # Tensor: rs[nwave],inta[nwave] 
        # Tensor: distances[neighbour*numatom*nbatch,1]
        # return: radial[neighbour*numatom*nbatch,nwave]
        distances=distances.view(-1,1)
        radial=torch.empty((distances.shape[0],self.rs.shape[1]),dtype=distances.dtype,device=distances.device)
        for itype in range(self.rs.shape[0]):
            mask = (species_ == itype)
            ele_index = torch.nonzero(mask).view(-1)
            if ele_index.shape[0]>0:
                part_radial=torch.exp(-self.inta[itype:itype+1]*torch.square \
                (distances.index_select(0,ele_index)-self.rs[itype:itype+1]))
                radial.masked_scatter_(mask.view(-1,1),part_radial)
        return radial
    
    def cutoff_cosine(self,distances):
        # assuming all elements in distances are smaller than cutoff
        # return cutoff_cosine[neighbour*numatom*nbatch]
        return torch.square(0.5 * torch.cos(distances * (np.pi / self.cutoff)) + 0.5)
    
    def angular(self,dist_vec):
        #  Tensor: dist_vec[neighbour*numatom*nbatch,3]
        # return: angular[neighbour*numatom*nbatch,npara[0]+npara[1]+...+npara[ipsin]]
        totneighbour=dist_vec.shape[0]
        dist_vec=dist_vec.permute(1,0).contiguous()
        orbital=dist_vec
        angular=torch.cat((torch.ones((1,totneighbour),dtype=dist_vec.dtype,device=dist_vec.device),dist_vec),dim=0)
        num=2
        for ipsin in range(1,int(self.ENIM[3])):
            orbital=torch.einsum("ji,ki -> jki",orbital,dist_vec).reshape(-1,totneighbour)
            if ipsin+1==self.nipsin[num]:
               angular=torch.cat((angular,orbital),dim=0)
               num+=1
        return angular  
    
    def forward(self,cart,neigh_list,shifts,species):
        """
        # input cart: coordinates (nbatch*numatom,3)
        # input shifts: coordinates shift values (unit cell)
        # input numatoms: number of atoms for each configuration
        # atom_index: neighbour list indice
        # species: indice for element of each atom
        """ 
        numatom=cart.shape[0]
        neigh_species=species.index_select(0,neigh_list[1])
        selected_cart = cart.index_select(0, neigh_list.view(-1)).view(2, -1, 3)
        dist_vec = selected_cart[0] - selected_cart[1]-shifts
        distances = torch.linalg.norm(dist_vec,dim=-1)
        dist_vec = dist_vec/distances.view(-1,1)
        angular=self.angular(dist_vec)
        orbital = torch.einsum("ji,i,ik -> ijk",angular,self.cutoff_cosine(distances),\
        self.gaussian(distances,neigh_species))
        orb_coeff=self.params.index_select(0,species)
        density=self.obtain_orb_coeff(numatom,orbital,neigh_list,orb_coeff)
        for ioc_loop, (_, m) in enumerate(self.ocmod.items()):
            orb_coeff=m(density,species)+orb_coeff
            density=self.obtain_orb_coeff(numatom,orbital,neigh_list,orb_coeff)
        return density.view(numatom,-1)

    def obtain_orb_coeff(self,numatom:int,orbital,neigh_list,orb_coeff):
        expandpara=orb_coeff.index_select(0,neigh_list[1]).view(-1,self.nipsin.shape[0],self.rs.shape[1]).index_select(1,self.index_para)
        worbital=expandpara*orbital
        sum_worbital=torch.zeros((numatom,orbital.shape[1],self.rs.shape[1]),dtype=orb_coeff.dtype,device=orb_coeff.device)
        sum_worbital=torch.index_add(sum_worbital,0,neigh_list[0],worbital)
        part_den=torch.square(sum_worbital)
        density=torch.zeros((numatom,self.nipsin.shape[0],self.rs.shape[1]),dtype=orb_coeff.dtype,device=orb_coeff.device)
        density=torch.index_add(density,1,self.index_para,part_den)
        return density.view(numatom,-1)

import torch
#import opt_einsum as oe

class Neigh_List(torch.nn.Module):
    def __init__(self,cutoff:float,nlinked:int):
        # nliked used for the periodic boundary condition in cell linked list
        super(Neigh_List,self).__init__()
        self.cutoff=cutoff
        self.cell_list=self.cutoff/nlinked
        r1 = torch.arange(-nlinked, nlinked + 1)
        self.linked=torch.cartesian_prod(r1, r1, r1).view(1,-1,3)

    def forward(self,period_table,coordinates,cell,mass):
        """Compute pairs of atoms that are neighbors
    
        Arguments:
            pbc (:class:`torch.double`): periodic boundary condition for each dimension
            coordinates (:class:`torch.Tensor`): tensor of shape
                (molecules, atoms, 3) for atom coordinates.
            cell (:class:`torch.Tensor`): tensor of shape (3, 3) of the three vectors
                defining unit cell: tensor([[x1, y1, z1], [x2, y2, z2], [x3, y3, z3]])
            cutoff (float): the cutoff inside which atoms are considered pairs
            shifts (:class:`torch.Tensor`): tensor of shape (?, 3) storing shifts
        """
        numatom=coordinates.shape[0]
        inv_cell=torch.inverse(cell)
        inv_coor=torch.einsum("ij,jk -> ik", coordinates, inv_cell)
        deviation_coor=torch.round(inv_coor-inv_coor[0])
        inv_coor=inv_coor-deviation_coor
        coordinates[:,:]=torch.einsum("ij,jk -> ik",inv_coor,cell)
        totmass=torch.sum(mass)
        com=torch.einsum('i,ij->j',mass,coordinates)/totmass
        coordinates[:,:]=coordinates-com[None,:]
        num_repeats = torch.ceil(torch.min(self.cutoff/torch.abs(cell),dim=0)[0]).to(torch.int)
        # the number of periodic image in each direction
        num_repeats = period_table*num_repeats
        num_repeats_up = (num_repeats+1).detach()
        num_repeats_down = (-num_repeats).detach()
        r1 = torch.arange(num_repeats_down[0], num_repeats_up[0], device=coordinates.device)
        r2 = torch.arange(num_repeats_down[1], num_repeats_up[1], device=coordinates.device)
        r3 = torch.arange(num_repeats_down[2], num_repeats_up[2], device=coordinates.device)
        shifts=torch.cartesian_prod(r1, r2, r3).to(coordinates.dtype)
        #shifts=oe.contract("ij,jk ->ik",shifts,cell,backend="torch")
        shifts=torch.einsum("ij,jk ->ik",shifts,cell)
        num_shifts = shifts.shape[0]
        all_shifts = torch.arange(num_shifts, device=coordinates.device)
        all_atoms = torch.arange(numatom, device=coordinates.device)
        prod = torch.cartesian_prod(all_shifts,all_atoms).t().contiguous()
        # used the modified cell_linked algorithm determine the neighbour atoms
        # cut the box with periodic image expand to the ori cell+cutoff in each direction
        # deviation for prevent the min point on the border
        mincoor=torch.min(coordinates,0)[0]-self.cutoff-1e-6
        coordinates=coordinates-mincoor
        maxcoor=torch.max(coordinates,0)[0]+self.cutoff
        image=(coordinates[None,:,:]+shifts[:,None,:]).view(-1,3)
        # get the index in the range (ori_cell-rc,ori_cell+rs) in  each direction
        mask=torch.nonzero(((image<maxcoor)*(image>0)).all(1)).view(-1)
        image_mask=image.index_select(0,mask)
        # save the index(shifts, atoms) for each atoms in the modified cell 
        prod=prod.index_select(1,mask)
        ori_image_index=torch.floor(coordinates/self.cell_list)
        # the central atoms with its linked cell index
        cell_linked=self.linked.expand(numatom,-1,3).to(coordinates.device)
        neigh_cell=ori_image_index[:,None,:]+cell_linked
        # all the index for each atoms in the modified cell   
        image_index=torch.floor(image_mask/self.cell_list)
        max_cell_index=torch.ceil(maxcoor/self.cell_list)
        neigh_cell_index=neigh_cell[:,:,2]*max_cell_index[1]*max_cell_index[0]+\
        neigh_cell[:,:,1]*max_cell_index[0]+neigh_cell[:,:,0]
        nimage_index=image_index[:,2]*max_cell_index[1]*max_cell_index[0]+\
        image_index[:,1]*max_cell_index[0]+image_index[:,0]
        dim_image_index=nimage_index.shape[0]
        mask_neigh=torch.nonzero(neigh_cell_index[:,None,:]==nimage_index[None,:,None])
        atom_index=mask_neigh[:,0:2]
        atom_index=atom_index.t().contiguous()
        # step 5, compute distances, and find all pairs within cutoff
        selected_coordinate1 = coordinates.index_select(0, atom_index[0])
        selected_coordinate2 = image_mask.index_select(0, atom_index[1])
        distances = (selected_coordinate1 - selected_coordinate2).norm(2, -1)
        pair_index = torch.nonzero((distances< self.cutoff)*(distances>0.001)).reshape(-1)
        neigh_index = atom_index[:,pair_index]
        tmp=prod.index_select(1,neigh_index[1])
        neigh_list=torch.vstack((neigh_index[0],tmp[1]))
        shifts = shifts.index_select(0, tmp[0])
        return neigh_list, shifts
import torch
from collections import OrderedDict
from torch import nn
from torch.nn import Linear,Dropout,BatchNorm1d,Sequential,LayerNorm
from torch.nn import Softplus,GELU,Tanh,SiLU
from torch.nn.init import xavier_normal_,zeros_,constant_
import numpy as np
#import pysnooper for dbug

class ResBlock(nn.Module):
    def __init__(self, nl, actfun, dropout_p, table_norm=True):
        super(ResBlock, self).__init__()
        # activation function used for the nn module
        nhid=len(nl)-1
        sumdrop=np.sum(dropout_p)
        modules=[]
        for i in range(1,nhid):
            if table_norm: modules.append(LayerNorm(nl[i]))
            modules.append(actfun)
            if sumdrop>=0.0001: modules.append(Dropout(p=dropout_p[i-1]))
            #bias = not(i==nhid-1)
            linear=Linear(nl[i],nl[i+1])
            if i==nhid-1: 
                zeros_(linear.weight)
            else:
                xavier_normal_(linear.weight)
            zeros_(linear.bias)
            modules.append(linear)
        self.resblock=Sequential(*modules)

    def forward(self, x):
        out = self.resblock(x)
        return out + x

#==================for get the atomic energy=======================================
class NNMod(torch.nn.Module):
   def __init__(self,maxnumtype,outputneuron,atomtype,nblock,nl,activate,dropout_p,initpot=0.0,table_norm=True):
      """
      maxnumtype: is the maximal element
      nl: is the neural network structure;
      actfun: activation function 
      outputneuron: the number of output neuron of neural network
      atomtype: elements in all systems
      """
      super(NNMod,self).__init__()
      # activation function used for the nn module
      if activate=='Softplus':
          actfun=Softplus()
      elif activate=='Gelu':
          actfun=GELU()
      elif activate=='tanh':
          actfun=Tanh()
      elif activate=='SiLU':
          actfun=SiLU()
      self.register_buffer("initpot",torch.Tensor([initpot]))
      # create the structure of the nn     
      self.outputneuron=outputneuron
      elemental_nets=OrderedDict()
      sumdrop=np.sum(dropout_p)
      with torch.no_grad():
          if nblock==1:
              nl.append(outputneuron)
              nhid=len(nl)-2
              for ele in atomtype:
                  modules=[]
                  for i in range(nhid):
                      linear=Linear(nl[i],nl[i+1])
                      xavier_normal_(linear.weight)
                      zeros_(linear.bias)
                      #xavier initialization (normal distribution)
                      modules.append(linear)
                      if table_norm: modules.append(LayerNorm(nl[i+1]))
                      modules.append(actfun)
                      if sumdrop>=0.0001: modules.append(Dropout(p=dropout_p[i]))
                  linear=Linear(nl[nhid],nl[nhid+1])
                  zeros_(linear.weight)
                  zeros_(linear.bias)
                  modules.append(linear)
                  elemental_nets[ele] = Sequential(*modules)
          else:
              nl.append(nl[1])
              nhid=len(nl)-1
              for ele in atomtype:
                  modules=[]
                  linear=Linear(nl[0],nl[1])
                  xavier_normal_(linear.weight)
                  # xavier initialization (normal distribution)
                  modules.append(linear)
                  for iblock in range(nblock):
                      modules.append( * [ResBlock(nl,actfun,dropout_p,table_norm=table_norm)])
                  modules.append(actfun)
                  linear=Linear(nl[nhid],self.outputneuron)
                  zeros_(linear.weight)
                  zeros_(linear.bias)
                  modules.append(linear)
                  elemental_nets[ele] = Sequential(*modules)
      self.elemental_nets=nn.ModuleDict(elemental_nets)

#   @pysnooper.snoop('out',depth=2)   for debug
   def forward(self,density,species):    
      # elements: dtype: LongTensor store the index of elements of each center atom
      output = torch.zeros((density.shape[0],self.outputneuron), dtype=density.dtype, device=density.device)
      for itype, (_, m) in enumerate(self.elemental_nets.items()):
          mask = (species == itype)
          ele_index = torch.nonzero(mask).view(-1)
          if ele_index.shape[0] > 0:
              ele_den = density[ele_index]
              output[ele_index] = m(ele_den)
      return output
import torch
import numpy as np
import os
from pes.density import *
from pes.MODEL import *
from pes.get_neigh import *

class PES(torch.nn.Module):
    def __init__(self,nlinked=1):
        super(PES, self).__init__()
        #========================set the global variable for using the exec=================
        global nblock, nl, dropout_p, activate, table_norm
        global oc_loop,oc_nblock, oc_nl, oc_dropout_p, oc_activate, oc_table_norm
        global nwave, neigh_atoms, cutoff, nipsin, atomtype
        # global parameters for input_nn
        nblock = 1                    # nblock>=2  resduial NN block will be employed nblock=1: simple feedforward nn
        nl=[256,128,64,32]                # NN structure
        dropout_p=[0.0,0.0,0.0]       # dropout probability for each hidden layer
        activate = 'Softplus'         # activate function: "Gelu", "tanh", "Softplus" are supported
        table_norm= False
        oc_loop = 0
        oc_nl = [64,32]          # neural network architecture   
        oc_nblock = 1
        oc_dropout_p=[0.0,0.0,0.0,0.0]
        #=====================act fun===========================
        oc_activate = 'Softplus'          # default "Softplus", optional "Gelu", "tanh"
        #========================queue_size sequence for laod data into gpu
        oc_table_norm=False
        
        #======================read input_nn==================================
        with open('para/input_nn','r') as f1:
           while True:
              tmp=f1.readline()
              if not tmp: break
              string=tmp.strip()
              if len(string)!=0:
                  if string[0]=='#':
                     pass
                  else:
                     m=string.split('#')
                     exec(m[0],globals())
        # define the outputneuron of NN
        outputneuron=1
        #======================read input_nn=============================================
        nipsin=[0,1,2]
        cutoff=4.0
        nwave=12
        with open('para/input_density','r') as f1:
           while True:
              tmp=f1.readline()
              if not tmp: break
              string=tmp.strip()
              if len(string)!=0:
                  if string[0]=='#':
                     pass
                  else:
                     m=string.split('#')
                     exec(m[0],globals())
        
        dropout_p=np.array(dropout_p)
        oc_dropout_p=np.array(oc_dropout_p)
        maxnumtype=len(atomtype)
        #========================use for read rs/inta or generate rs/inta================
        if 'rs' in globals().keys():
            rs=torch.from_numpy(np.array(rs))
            inta=torch.from_numpy(np.array(inta))
            nwave=rs.shape[1]
        else:
            inta=torch.ones((maxnumtype,nwave))
            rs=torch.stack([torch.linspace(0,cutoff,nwave) for itype in range(maxnumtype)],dim=0)
        #======================for orbital================================
        ipsin=len(nipsin)
        nipsin=torch.Tensor(nipsin)
        norbit=nwave*ipsin
        #========================nn structure========================
        nl.insert(0,int(norbit))
        oc_nl.insert(0,int(norbit))
        #================read the periodic boundary condition, element and mass=========
        self.cutoff=cutoff
        ocmod_list=[]
        for ioc_loop in range(oc_loop):
            ocmod_list.append(NNMod(maxnumtype,norbit,atomtype,oc_nblock,list(oc_nl),\
            oc_activate,oc_dropout_p,table_norm=oc_table_norm))
        self.density=GetDensity(rs,inta,cutoff,nipsin,ocmod_list)
        self.nnmod=NNMod(maxnumtype,outputneuron,atomtype,nblock,list(nl),activate,dropout_p,table_norm=table_norm)
        #================================================nn module==================================================
        self.neigh_list=Neigh_List(cutoff,nlinked)
     
    def forward(self,period_table,cart,cell,species,mass):
        cart=cart.detach().clone()
        neigh_list, shifts=self.neigh_list(period_table,cart,cell,mass)
        cart.requires_grad_(True)
        density=self.density(cart,neigh_list,shifts,species)
        output = self.nnmod(density,species)
        dipole=torch.einsum("i,ij -> j",output.view(-1),cart)
        return dipole.detach()
import dm.PES as PES
from collections import OrderedDict
import torch
def jit_pes():
    init_pes=PES.PES()
    state_dict = torch.load("EANN.pth",map_location='cpu')
    new_state_dict = OrderedDict()
    for k, v in state_dict['eannparam'].items():
        name = k[7:] # remove `module.`
        new_state_dict[name] = v
    init_pes.load_state_dict(new_state_dict)
    scripted_pes=torch.jit.script(init_pes)
    for params in scripted_pes.parameters():
        params.requires_grad=False
    scripted_pes.save("EANN_DM_DOUBLE.pt")
    scripted_pes.to(torch.float32)
    scripted_pes.save("EANN_DM_FLOAT.pt")
